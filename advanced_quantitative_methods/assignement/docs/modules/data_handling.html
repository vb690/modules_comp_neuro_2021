<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>modules.data_handling API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>modules.data_handling</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">__docformat__ = &#34;google&#34;

import os

import pandas as pd

import numpy as np

from tqdm import tqdm


class ExperimentParser:
    &#34;&#34;&#34;A Class parsing and holding experiment results.

    Attributes:
        experiment_dir (str): string specifying where the .dat files to be
            parsed are located.
    &#34;&#34;&#34;
    def __init__(self, experiment_dir):
        &#34;&#34;&#34;Instantiate ExperimentParser with experiment_dir
        &#34;&#34;&#34;
        self.experiment_dir = experiment_dir

        # this are created empty when the parser is instatiated
        self.subject_code = None
        self.counterbalance_code = None
        self.task_format_code = None
        self.condition_code = None
        self.phase_code = None

    @staticmethod
    def get_logs(line, is_test):
        &#34;&#34;&#34;Static method for parsing and standardizing experiment logs from
        the .dat file.

            Args:
                line (list): list containing the the experiment log for a
                    a trial in the .dat file.
                is_test (bool): bolean specifying if the log is coming from the
                    training or test phase.

            Returns:
                logs (list): a list of floats containing the parsed experiment
                    log.
        &#34;&#34;&#34;
        # test mode has a different format
        # and doesn&#39;t have outcome or reward
        if is_test:
            line.insert(5, None)
            line.insert(7, None)
        else:
            # in training mode
            # we have to infer response given
            # from response rewarded
            line.insert(6, None)
        # if at this point len(line) &lt; 9
        # response time is missing (AnoF condition)
        while len(line) &lt; 9:
            line.append(None)
        logs = [np.float64(log) if log is not None else log for log in line]
        return logs

    @staticmethod
    def get_prob_norm_correct(cues,
                              mapping={0: 0.25, 1: 0.25, 2: -0.25, 3: -0.25}):
        &#34;&#34;&#34;Compute the probability of a normative correct response in a trial
        given cues probability mapping.

            Args:
                cues (array): a binary numpy array reporting which cues were
                    present in the trial.
                mapping (dict): a dictionary with keys indicating the index of
                    a specific cue in cues (e.g. 0 is cue in position 0) and
                    values the changes in probability for a specific outcome to
                    occour.

            Returns:
                p (float): a float specifying the probability of a target
                    outcome to happen.
        &#34;&#34;&#34;
        mapping = np.array([mapping[cue] for cue in range(len(mapping))])
        cues = np.argwhere(cues.values == 1).flatten()
        p = 0.5 + mapping[cues].sum()
        return p

    @staticmethod
    def get_norm_correct(prob_norm_correct):
        &#34;&#34;&#34;Get the normatively correct response given a probability.

            Args:
                prob_norm_correct (float): a float specifying the probability
                    of a target outcome to happen.

            Returns:
                norm_correct (int): integer or None specifying which of two
                    target outcomes is the normatively correct one.
        &#34;&#34;&#34;
        if prob_norm_correct &lt; 0.5:
            return 2
        elif prob_norm_correct &gt; 0.5:
            return 1
        else:
            return None

    def __get_subject_data(self, text):
        &#34;&#34;&#34;Private method for turning text data extracted from a subject
        .dat file in a format suitable to be transformed in a pandas DataFrame.

            Args:
                text (list): is a list of strings containg the logs from all
                    the trials extracted from the .dat file.

            Returns:
                subject_data (list): list of lists containing all the trails
                    logs extracted for a specific subject.
        &#34;&#34;&#34;
        subject_data = []
        fnoa_order = None

        for line in tqdm(text, leave=False):

            if &#39;%&#39; in line:  # ignore values with % as in forum
                continue
            elif &#39;Map&#39; in line:
                continue
            # APA recommend the use of participant tho
            elif &#39;Subject&#39; in line:
                self.subject_code = line.split()[0]
            elif &#39;Counterbal&#39; in line:
                self.counterbalance_code = line.split()[0]
            elif &#39;Format&#39; in line:
                self.task_format_code = line.split()[0]
            elif &#39;Condition&#39; in line:
                self.condition_code = line.split()[0]
                # we could verify which counterbal condition
                # has FnoA first but it would be kinda cheating
                if fnoa_order is None:
                    fnoa_order = 1 if \
                        self.condition_code == &#39;FnoA&#39; else 2
            elif &#39;Training&#39; in line:
                self.phase_code = line.split()[0]
            elif &#39;Test&#39; in line:
                self.phase_code = line.split()[0]
            else:
                experiment_info = [
                    self.subject_code,
                    self.counterbalance_code,
                    self.task_format_code,
                    self.condition_code,
                    self.phase_code,
                    fnoa_order
                ]
                experiment_logs = self.get_logs(
                    line=line.split(),
                    is_test=self.phase_code == &#39;Test&#39;
                )
                subject_data.append(experiment_info + experiment_logs)

        return subject_data

    def parse_dat_files(self):
        &#34;&#34;&#34;Parse the .dat file into a Pandas DataFrame and setting it as
        an attributed to the parser.

            Args:
                None

            Returns:
                None
        &#34;&#34;&#34;
        experiment_data = []

        for filename in tqdm(os.listdir(self.experiment_dir)):

            with open(f&#39;{self.experiment_dir}{filename}&#39;) as infile:

                text = infile.read()
                text = text.split(&#39;\n&#39;)
                text = [
                    txt_str.strip() for txt_str in text if txt_str != &#39;&#39;
                ]

                subject_data = self.__get_subject_data(text=text)

                subject_data = pd.DataFrame(
                    np.array(subject_data),
                    columns=[
                        &#39;subno&#39;,
                        &#39;counterbal&#39;,
                        &#39;format&#39;,
                        &#39;condition&#39;,
                        &#39;phase&#39;,
                        &#39;fnoa_order&#39;,
                        &#39;trial_n&#39;,
                        &#39;cue_1&#39;,
                        &#39;cue_2&#39;,
                        &#39;cue_3&#39;,
                        &#39;cue_4&#39;,
                        &#39;outcome&#39;,
                        &#39;resp_given&#39;,
                        &#39;resp_rewar&#39;,
                        &#39;resp_time&#39;
                    ]
                )
                # we standardize response encoding because it is infuriating
                # so now 1 is 1 in every field and 2 is 2 in every field
                subject_data[&#39;outcome&#39;] = subject_data[&#39;outcome&#39;].map(
                    {0: 2, 1: 1}
                )

            experiment_data.append(subject_data)

        experiment_data = pd.concat(
            experiment_data,
            ignore_index=True
        )

        # compute the normatively correct response
        experiment_data[&#39;prob_outcome_1&#39;] = experiment_data[
            [f&#39;cue_{cue_number}&#39; for cue_number in range(1, 5)]
        ].apply(
            self.get_prob_norm_correct,
            axis=1
        )
        experiment_data[&#39;resp_norm_corr&#39;] = \
            experiment_data[&#39;prob_outcome_1&#39;].apply(
                self.get_norm_correct
            )

        # define the include vector
        # hard-code this since it is tricky to programmatically alter
        # a slice of pandas DataFrame over multiple conditions
        experiment_data[&#39;include&#39;] = 1
        experiment_data.loc[
            (experiment_data[&#39;condition&#39;] == &#39;FnoA&#39;) &amp;
            (experiment_data[&#39;trial_n&#39;].isin([53, 54, 55, 56])) &amp;
            (experiment_data[&#39;fnoa_order&#39;] == 1),
            &#39;include&#39;
        ] = 0
        experiment_data.loc[
            experiment_data[&#39;include&#39;] == 0, &#39;resp_rewar&#39;
        ] = None

        # infer the response given based on reward
        experiment_data.loc[
            experiment_data[&#39;resp_rewar&#39;] == 1, &#39;resp_given&#39;
        ] = experiment_data[&#39;outcome&#39;]
        # when it is not rewarded we
        # invert the response given
        experiment_data.loc[
            experiment_data[&#39;resp_rewar&#39;] == 0, &#39;resp_given&#39;
        ] = experiment_data[&#39;outcome&#39;].map(
            {
                1: 2, 2: 1
            }
        )

        # re arrange columns
        experiment_data = experiment_data[
            [
                &#39;subno&#39;,
                &#39;fnoa_order&#39;,
                &#39;format&#39;,
                &#39;counterbal&#39;,
                &#39;condition&#39;,
                &#39;trial_n&#39;,
                &#39;phase&#39;,
                &#39;include&#39;,
                &#39;cue_1&#39;,
                &#39;cue_2&#39;,
                &#39;cue_3&#39;,
                &#39;cue_4&#39;,
                &#39;prob_outcome_1&#39;,
                &#39;outcome&#39;,
                &#39;resp_given&#39;,
                &#39;resp_norm_corr&#39;,
                &#39;resp_time&#39;,
                &#39;resp_rewar&#39;
            ]
        ]

        experiment_data = experiment_data.sort_values(
            [&#39;subno&#39;, &#39;condition&#39;, &#39;trial_n&#39;]
        ).reset_index(drop=True)
        setattr(self, &#39;experiment_data&#39;, experiment_data)

        return None

    def get_data(self, filters=None):
        &#34;&#34;&#34;Get the stored parsed experiment data applying a series of filters
        if sepcified. A copy of the data is always returned.

            Args:
                filters (dict): a dictionary with keys indicating the column
                    on which the filter is applied and values specifying the
                    value thatthe column has to match. The filters are applied
                    in sequence but order cannot be guaranteed.

            Returns:
                filtered_data (DataFrame): a pandas DataFrame with the
                    experiment data.
        &#34;&#34;&#34;
        filtered_data = self.experiment_data.copy()
        if filters is not None:
            for column_name, value in filters.items():

                filtered_data = filtered_data[
                    filtered_data[column_name] == value
                ]

            return filtered_data
        else:
            return filtered_data


def merge_sav_file(left_df, path, keys):
    &#34;&#34;&#34;Utility function for merging a pandas DataFrame with sav file
    on a list of keys (i.e. columns).

        Args:
            left_df (DataFrame): a pandas DataFrame that wil be joined with
                the .sav file.
            path (str): a string specifying the location of the .sav file.
            keys (list): a list of strings specifying on which columns the
                .sav file will be joined.

        Returns:
            merged (DataFrame): a pandas DataFrame resulting from joining
                left_df with the sav file on keys.
    &#34;&#34;&#34;
    sav_df = pd.read_spss(
        path
    )
    merged = pd.merge(
        left_df,
        sav_df,
        how=&#39;left&#39;,
        on=keys
    )
    return merged</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="modules.data_handling.merge_sav_file"><code class="name flex">
<span>def <span class="ident">merge_sav_file</span></span>(<span>left_df, path, keys)</span>
</code></dt>
<dd>
<div class="desc"><p>Utility function for merging a pandas DataFrame with sav file
on a list of keys (i.e. columns).</p>
<pre><code>Args:
    left_df (DataFrame): a pandas DataFrame that wil be joined with
        the .sav file.
    path (str): a string specifying the location of the .sav file.
    keys (list): a list of strings specifying on which columns the
        .sav file will be joined.

Returns:
    merged (DataFrame): a pandas DataFrame resulting from joining
        left_df with the sav file on keys.
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def merge_sav_file(left_df, path, keys):
    &#34;&#34;&#34;Utility function for merging a pandas DataFrame with sav file
    on a list of keys (i.e. columns).

        Args:
            left_df (DataFrame): a pandas DataFrame that wil be joined with
                the .sav file.
            path (str): a string specifying the location of the .sav file.
            keys (list): a list of strings specifying on which columns the
                .sav file will be joined.

        Returns:
            merged (DataFrame): a pandas DataFrame resulting from joining
                left_df with the sav file on keys.
    &#34;&#34;&#34;
    sav_df = pd.read_spss(
        path
    )
    merged = pd.merge(
        left_df,
        sav_df,
        how=&#39;left&#39;,
        on=keys
    )
    return merged</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="modules.data_handling.ExperimentParser"><code class="flex name class">
<span>class <span class="ident">ExperimentParser</span></span>
<span>(</span><span>experiment_dir)</span>
</code></dt>
<dd>
<div class="desc"><p>A Class parsing and holding experiment results.</p>
<h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>experiment_dir</code></strong> :&ensp;<code>str</code></dt>
<dd>string specifying where the .dat files to be
parsed are located.</dd>
</dl>
<p>Instantiate ExperimentParser with experiment_dir</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ExperimentParser:
    &#34;&#34;&#34;A Class parsing and holding experiment results.

    Attributes:
        experiment_dir (str): string specifying where the .dat files to be
            parsed are located.
    &#34;&#34;&#34;
    def __init__(self, experiment_dir):
        &#34;&#34;&#34;Instantiate ExperimentParser with experiment_dir
        &#34;&#34;&#34;
        self.experiment_dir = experiment_dir

        # this are created empty when the parser is instatiated
        self.subject_code = None
        self.counterbalance_code = None
        self.task_format_code = None
        self.condition_code = None
        self.phase_code = None

    @staticmethod
    def get_logs(line, is_test):
        &#34;&#34;&#34;Static method for parsing and standardizing experiment logs from
        the .dat file.

            Args:
                line (list): list containing the the experiment log for a
                    a trial in the .dat file.
                is_test (bool): bolean specifying if the log is coming from the
                    training or test phase.

            Returns:
                logs (list): a list of floats containing the parsed experiment
                    log.
        &#34;&#34;&#34;
        # test mode has a different format
        # and doesn&#39;t have outcome or reward
        if is_test:
            line.insert(5, None)
            line.insert(7, None)
        else:
            # in training mode
            # we have to infer response given
            # from response rewarded
            line.insert(6, None)
        # if at this point len(line) &lt; 9
        # response time is missing (AnoF condition)
        while len(line) &lt; 9:
            line.append(None)
        logs = [np.float64(log) if log is not None else log for log in line]
        return logs

    @staticmethod
    def get_prob_norm_correct(cues,
                              mapping={0: 0.25, 1: 0.25, 2: -0.25, 3: -0.25}):
        &#34;&#34;&#34;Compute the probability of a normative correct response in a trial
        given cues probability mapping.

            Args:
                cues (array): a binary numpy array reporting which cues were
                    present in the trial.
                mapping (dict): a dictionary with keys indicating the index of
                    a specific cue in cues (e.g. 0 is cue in position 0) and
                    values the changes in probability for a specific outcome to
                    occour.

            Returns:
                p (float): a float specifying the probability of a target
                    outcome to happen.
        &#34;&#34;&#34;
        mapping = np.array([mapping[cue] for cue in range(len(mapping))])
        cues = np.argwhere(cues.values == 1).flatten()
        p = 0.5 + mapping[cues].sum()
        return p

    @staticmethod
    def get_norm_correct(prob_norm_correct):
        &#34;&#34;&#34;Get the normatively correct response given a probability.

            Args:
                prob_norm_correct (float): a float specifying the probability
                    of a target outcome to happen.

            Returns:
                norm_correct (int): integer or None specifying which of two
                    target outcomes is the normatively correct one.
        &#34;&#34;&#34;
        if prob_norm_correct &lt; 0.5:
            return 2
        elif prob_norm_correct &gt; 0.5:
            return 1
        else:
            return None

    def __get_subject_data(self, text):
        &#34;&#34;&#34;Private method for turning text data extracted from a subject
        .dat file in a format suitable to be transformed in a pandas DataFrame.

            Args:
                text (list): is a list of strings containg the logs from all
                    the trials extracted from the .dat file.

            Returns:
                subject_data (list): list of lists containing all the trails
                    logs extracted for a specific subject.
        &#34;&#34;&#34;
        subject_data = []
        fnoa_order = None

        for line in tqdm(text, leave=False):

            if &#39;%&#39; in line:  # ignore values with % as in forum
                continue
            elif &#39;Map&#39; in line:
                continue
            # APA recommend the use of participant tho
            elif &#39;Subject&#39; in line:
                self.subject_code = line.split()[0]
            elif &#39;Counterbal&#39; in line:
                self.counterbalance_code = line.split()[0]
            elif &#39;Format&#39; in line:
                self.task_format_code = line.split()[0]
            elif &#39;Condition&#39; in line:
                self.condition_code = line.split()[0]
                # we could verify which counterbal condition
                # has FnoA first but it would be kinda cheating
                if fnoa_order is None:
                    fnoa_order = 1 if \
                        self.condition_code == &#39;FnoA&#39; else 2
            elif &#39;Training&#39; in line:
                self.phase_code = line.split()[0]
            elif &#39;Test&#39; in line:
                self.phase_code = line.split()[0]
            else:
                experiment_info = [
                    self.subject_code,
                    self.counterbalance_code,
                    self.task_format_code,
                    self.condition_code,
                    self.phase_code,
                    fnoa_order
                ]
                experiment_logs = self.get_logs(
                    line=line.split(),
                    is_test=self.phase_code == &#39;Test&#39;
                )
                subject_data.append(experiment_info + experiment_logs)

        return subject_data

    def parse_dat_files(self):
        &#34;&#34;&#34;Parse the .dat file into a Pandas DataFrame and setting it as
        an attributed to the parser.

            Args:
                None

            Returns:
                None
        &#34;&#34;&#34;
        experiment_data = []

        for filename in tqdm(os.listdir(self.experiment_dir)):

            with open(f&#39;{self.experiment_dir}{filename}&#39;) as infile:

                text = infile.read()
                text = text.split(&#39;\n&#39;)
                text = [
                    txt_str.strip() for txt_str in text if txt_str != &#39;&#39;
                ]

                subject_data = self.__get_subject_data(text=text)

                subject_data = pd.DataFrame(
                    np.array(subject_data),
                    columns=[
                        &#39;subno&#39;,
                        &#39;counterbal&#39;,
                        &#39;format&#39;,
                        &#39;condition&#39;,
                        &#39;phase&#39;,
                        &#39;fnoa_order&#39;,
                        &#39;trial_n&#39;,
                        &#39;cue_1&#39;,
                        &#39;cue_2&#39;,
                        &#39;cue_3&#39;,
                        &#39;cue_4&#39;,
                        &#39;outcome&#39;,
                        &#39;resp_given&#39;,
                        &#39;resp_rewar&#39;,
                        &#39;resp_time&#39;
                    ]
                )
                # we standardize response encoding because it is infuriating
                # so now 1 is 1 in every field and 2 is 2 in every field
                subject_data[&#39;outcome&#39;] = subject_data[&#39;outcome&#39;].map(
                    {0: 2, 1: 1}
                )

            experiment_data.append(subject_data)

        experiment_data = pd.concat(
            experiment_data,
            ignore_index=True
        )

        # compute the normatively correct response
        experiment_data[&#39;prob_outcome_1&#39;] = experiment_data[
            [f&#39;cue_{cue_number}&#39; for cue_number in range(1, 5)]
        ].apply(
            self.get_prob_norm_correct,
            axis=1
        )
        experiment_data[&#39;resp_norm_corr&#39;] = \
            experiment_data[&#39;prob_outcome_1&#39;].apply(
                self.get_norm_correct
            )

        # define the include vector
        # hard-code this since it is tricky to programmatically alter
        # a slice of pandas DataFrame over multiple conditions
        experiment_data[&#39;include&#39;] = 1
        experiment_data.loc[
            (experiment_data[&#39;condition&#39;] == &#39;FnoA&#39;) &amp;
            (experiment_data[&#39;trial_n&#39;].isin([53, 54, 55, 56])) &amp;
            (experiment_data[&#39;fnoa_order&#39;] == 1),
            &#39;include&#39;
        ] = 0
        experiment_data.loc[
            experiment_data[&#39;include&#39;] == 0, &#39;resp_rewar&#39;
        ] = None

        # infer the response given based on reward
        experiment_data.loc[
            experiment_data[&#39;resp_rewar&#39;] == 1, &#39;resp_given&#39;
        ] = experiment_data[&#39;outcome&#39;]
        # when it is not rewarded we
        # invert the response given
        experiment_data.loc[
            experiment_data[&#39;resp_rewar&#39;] == 0, &#39;resp_given&#39;
        ] = experiment_data[&#39;outcome&#39;].map(
            {
                1: 2, 2: 1
            }
        )

        # re arrange columns
        experiment_data = experiment_data[
            [
                &#39;subno&#39;,
                &#39;fnoa_order&#39;,
                &#39;format&#39;,
                &#39;counterbal&#39;,
                &#39;condition&#39;,
                &#39;trial_n&#39;,
                &#39;phase&#39;,
                &#39;include&#39;,
                &#39;cue_1&#39;,
                &#39;cue_2&#39;,
                &#39;cue_3&#39;,
                &#39;cue_4&#39;,
                &#39;prob_outcome_1&#39;,
                &#39;outcome&#39;,
                &#39;resp_given&#39;,
                &#39;resp_norm_corr&#39;,
                &#39;resp_time&#39;,
                &#39;resp_rewar&#39;
            ]
        ]

        experiment_data = experiment_data.sort_values(
            [&#39;subno&#39;, &#39;condition&#39;, &#39;trial_n&#39;]
        ).reset_index(drop=True)
        setattr(self, &#39;experiment_data&#39;, experiment_data)

        return None

    def get_data(self, filters=None):
        &#34;&#34;&#34;Get the stored parsed experiment data applying a series of filters
        if sepcified. A copy of the data is always returned.

            Args:
                filters (dict): a dictionary with keys indicating the column
                    on which the filter is applied and values specifying the
                    value thatthe column has to match. The filters are applied
                    in sequence but order cannot be guaranteed.

            Returns:
                filtered_data (DataFrame): a pandas DataFrame with the
                    experiment data.
        &#34;&#34;&#34;
        filtered_data = self.experiment_data.copy()
        if filters is not None:
            for column_name, value in filters.items():

                filtered_data = filtered_data[
                    filtered_data[column_name] == value
                ]

            return filtered_data
        else:
            return filtered_data</code></pre>
</details>
<h3>Static methods</h3>
<dl>
<dt id="modules.data_handling.ExperimentParser.get_logs"><code class="name flex">
<span>def <span class="ident">get_logs</span></span>(<span>line, is_test)</span>
</code></dt>
<dd>
<div class="desc"><p>Static method for parsing and standardizing experiment logs from
the .dat file.</p>
<pre><code>Args:
    line (list): list containing the the experiment log for a
        a trial in the .dat file.
    is_test (bool): bolean specifying if the log is coming from the
        training or test phase.

Returns:
    logs (list): a list of floats containing the parsed experiment
        log.
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def get_logs(line, is_test):
    &#34;&#34;&#34;Static method for parsing and standardizing experiment logs from
    the .dat file.

        Args:
            line (list): list containing the the experiment log for a
                a trial in the .dat file.
            is_test (bool): bolean specifying if the log is coming from the
                training or test phase.

        Returns:
            logs (list): a list of floats containing the parsed experiment
                log.
    &#34;&#34;&#34;
    # test mode has a different format
    # and doesn&#39;t have outcome or reward
    if is_test:
        line.insert(5, None)
        line.insert(7, None)
    else:
        # in training mode
        # we have to infer response given
        # from response rewarded
        line.insert(6, None)
    # if at this point len(line) &lt; 9
    # response time is missing (AnoF condition)
    while len(line) &lt; 9:
        line.append(None)
    logs = [np.float64(log) if log is not None else log for log in line]
    return logs</code></pre>
</details>
</dd>
<dt id="modules.data_handling.ExperimentParser.get_norm_correct"><code class="name flex">
<span>def <span class="ident">get_norm_correct</span></span>(<span>prob_norm_correct)</span>
</code></dt>
<dd>
<div class="desc"><p>Get the normatively correct response given a probability.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>prob_norm_correct</code></strong> :&ensp;<code>float</code></dt>
<dd>a float specifying the probability
of a target outcome to happen.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>norm_correct (int): integer or None specifying which of two
target outcomes is the normatively correct one.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def get_norm_correct(prob_norm_correct):
    &#34;&#34;&#34;Get the normatively correct response given a probability.

        Args:
            prob_norm_correct (float): a float specifying the probability
                of a target outcome to happen.

        Returns:
            norm_correct (int): integer or None specifying which of two
                target outcomes is the normatively correct one.
    &#34;&#34;&#34;
    if prob_norm_correct &lt; 0.5:
        return 2
    elif prob_norm_correct &gt; 0.5:
        return 1
    else:
        return None</code></pre>
</details>
</dd>
<dt id="modules.data_handling.ExperimentParser.get_prob_norm_correct"><code class="name flex">
<span>def <span class="ident">get_prob_norm_correct</span></span>(<span>cues, mapping={0: 0.25, 1: 0.25, 2: -0.25, 3: -0.25})</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the probability of a normative correct response in a trial
given cues probability mapping.</p>
<pre><code>Args:
    cues (array): a binary numpy array reporting which cues were
        present in the trial.
    mapping (dict): a dictionary with keys indicating the index of
        a specific cue in cues (e.g. 0 is cue in position 0) and
        values the changes in probability for a specific outcome to
        occour.

Returns:
    p (float): a float specifying the probability of a target
        outcome to happen.
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def get_prob_norm_correct(cues,
                          mapping={0: 0.25, 1: 0.25, 2: -0.25, 3: -0.25}):
    &#34;&#34;&#34;Compute the probability of a normative correct response in a trial
    given cues probability mapping.

        Args:
            cues (array): a binary numpy array reporting which cues were
                present in the trial.
            mapping (dict): a dictionary with keys indicating the index of
                a specific cue in cues (e.g. 0 is cue in position 0) and
                values the changes in probability for a specific outcome to
                occour.

        Returns:
            p (float): a float specifying the probability of a target
                outcome to happen.
    &#34;&#34;&#34;
    mapping = np.array([mapping[cue] for cue in range(len(mapping))])
    cues = np.argwhere(cues.values == 1).flatten()
    p = 0.5 + mapping[cues].sum()
    return p</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="modules.data_handling.ExperimentParser.get_data"><code class="name flex">
<span>def <span class="ident">get_data</span></span>(<span>self, filters=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Get the stored parsed experiment data applying a series of filters
if sepcified. A copy of the data is always returned.</p>
<pre><code>Args:
    filters (dict): a dictionary with keys indicating the column
        on which the filter is applied and values specifying the
        value thatthe column has to match. The filters are applied
        in sequence but order cannot be guaranteed.

Returns:
    filtered_data (DataFrame): a pandas DataFrame with the
        experiment data.
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_data(self, filters=None):
    &#34;&#34;&#34;Get the stored parsed experiment data applying a series of filters
    if sepcified. A copy of the data is always returned.

        Args:
            filters (dict): a dictionary with keys indicating the column
                on which the filter is applied and values specifying the
                value thatthe column has to match. The filters are applied
                in sequence but order cannot be guaranteed.

        Returns:
            filtered_data (DataFrame): a pandas DataFrame with the
                experiment data.
    &#34;&#34;&#34;
    filtered_data = self.experiment_data.copy()
    if filters is not None:
        for column_name, value in filters.items():

            filtered_data = filtered_data[
                filtered_data[column_name] == value
            ]

        return filtered_data
    else:
        return filtered_data</code></pre>
</details>
</dd>
<dt id="modules.data_handling.ExperimentParser.parse_dat_files"><code class="name flex">
<span>def <span class="ident">parse_dat_files</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Parse the .dat file into a Pandas DataFrame and setting it as
an attributed to the parser.</p>
<pre><code>Args:
    None

Returns:
    None
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def parse_dat_files(self):
    &#34;&#34;&#34;Parse the .dat file into a Pandas DataFrame and setting it as
    an attributed to the parser.

        Args:
            None

        Returns:
            None
    &#34;&#34;&#34;
    experiment_data = []

    for filename in tqdm(os.listdir(self.experiment_dir)):

        with open(f&#39;{self.experiment_dir}{filename}&#39;) as infile:

            text = infile.read()
            text = text.split(&#39;\n&#39;)
            text = [
                txt_str.strip() for txt_str in text if txt_str != &#39;&#39;
            ]

            subject_data = self.__get_subject_data(text=text)

            subject_data = pd.DataFrame(
                np.array(subject_data),
                columns=[
                    &#39;subno&#39;,
                    &#39;counterbal&#39;,
                    &#39;format&#39;,
                    &#39;condition&#39;,
                    &#39;phase&#39;,
                    &#39;fnoa_order&#39;,
                    &#39;trial_n&#39;,
                    &#39;cue_1&#39;,
                    &#39;cue_2&#39;,
                    &#39;cue_3&#39;,
                    &#39;cue_4&#39;,
                    &#39;outcome&#39;,
                    &#39;resp_given&#39;,
                    &#39;resp_rewar&#39;,
                    &#39;resp_time&#39;
                ]
            )
            # we standardize response encoding because it is infuriating
            # so now 1 is 1 in every field and 2 is 2 in every field
            subject_data[&#39;outcome&#39;] = subject_data[&#39;outcome&#39;].map(
                {0: 2, 1: 1}
            )

        experiment_data.append(subject_data)

    experiment_data = pd.concat(
        experiment_data,
        ignore_index=True
    )

    # compute the normatively correct response
    experiment_data[&#39;prob_outcome_1&#39;] = experiment_data[
        [f&#39;cue_{cue_number}&#39; for cue_number in range(1, 5)]
    ].apply(
        self.get_prob_norm_correct,
        axis=1
    )
    experiment_data[&#39;resp_norm_corr&#39;] = \
        experiment_data[&#39;prob_outcome_1&#39;].apply(
            self.get_norm_correct
        )

    # define the include vector
    # hard-code this since it is tricky to programmatically alter
    # a slice of pandas DataFrame over multiple conditions
    experiment_data[&#39;include&#39;] = 1
    experiment_data.loc[
        (experiment_data[&#39;condition&#39;] == &#39;FnoA&#39;) &amp;
        (experiment_data[&#39;trial_n&#39;].isin([53, 54, 55, 56])) &amp;
        (experiment_data[&#39;fnoa_order&#39;] == 1),
        &#39;include&#39;
    ] = 0
    experiment_data.loc[
        experiment_data[&#39;include&#39;] == 0, &#39;resp_rewar&#39;
    ] = None

    # infer the response given based on reward
    experiment_data.loc[
        experiment_data[&#39;resp_rewar&#39;] == 1, &#39;resp_given&#39;
    ] = experiment_data[&#39;outcome&#39;]
    # when it is not rewarded we
    # invert the response given
    experiment_data.loc[
        experiment_data[&#39;resp_rewar&#39;] == 0, &#39;resp_given&#39;
    ] = experiment_data[&#39;outcome&#39;].map(
        {
            1: 2, 2: 1
        }
    )

    # re arrange columns
    experiment_data = experiment_data[
        [
            &#39;subno&#39;,
            &#39;fnoa_order&#39;,
            &#39;format&#39;,
            &#39;counterbal&#39;,
            &#39;condition&#39;,
            &#39;trial_n&#39;,
            &#39;phase&#39;,
            &#39;include&#39;,
            &#39;cue_1&#39;,
            &#39;cue_2&#39;,
            &#39;cue_3&#39;,
            &#39;cue_4&#39;,
            &#39;prob_outcome_1&#39;,
            &#39;outcome&#39;,
            &#39;resp_given&#39;,
            &#39;resp_norm_corr&#39;,
            &#39;resp_time&#39;,
            &#39;resp_rewar&#39;
        ]
    ]

    experiment_data = experiment_data.sort_values(
        [&#39;subno&#39;, &#39;condition&#39;, &#39;trial_n&#39;]
    ).reset_index(drop=True)
    setattr(self, &#39;experiment_data&#39;, experiment_data)

    return None</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="modules" href="index.html">modules</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="modules.data_handling.merge_sav_file" href="#modules.data_handling.merge_sav_file">merge_sav_file</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="modules.data_handling.ExperimentParser" href="#modules.data_handling.ExperimentParser">ExperimentParser</a></code></h4>
<ul class="">
<li><code><a title="modules.data_handling.ExperimentParser.get_data" href="#modules.data_handling.ExperimentParser.get_data">get_data</a></code></li>
<li><code><a title="modules.data_handling.ExperimentParser.get_logs" href="#modules.data_handling.ExperimentParser.get_logs">get_logs</a></code></li>
<li><code><a title="modules.data_handling.ExperimentParser.get_norm_correct" href="#modules.data_handling.ExperimentParser.get_norm_correct">get_norm_correct</a></code></li>
<li><code><a title="modules.data_handling.ExperimentParser.get_prob_norm_correct" href="#modules.data_handling.ExperimentParser.get_prob_norm_correct">get_prob_norm_correct</a></code></li>
<li><code><a title="modules.data_handling.ExperimentParser.parse_dat_files" href="#modules.data_handling.ExperimentParser.parse_dat_files">parse_dat_files</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>